An artificial general intelligence (AGI) is a hypothetical type of intelligent agent. If realized, an AGI could learn to accomplish any intellectual task that human beings or animals can perform. Alternatively, AGI has been defined as an autonomous system that surpasses human capabilities in the majority of economically valuable tasks. Creating AGI is a primary goal of some artificial intelligence research and of companies such as OpenAI, DeepMind, and Anthropic. AGI is a common topic in science fiction and futures studies.
The timeline for AGI development remains a subject of ongoing debate among researchers and experts. Some argue that it may be possible in years or decades, others maintain it might take a century or longer, and a minority believe it may never be achieved. Additionally, there is debate regarding whether modern large language models, such as GPT-4, are an early yet incomplete form of AGI or if new approaches are required.
Contention exists over the potential for AGI to pose a threat to humanity; for example, OpenAI treats it as an existential risk, while others find the development of AGI to be too remote to present a risk.
A 2020 survey identified 72 active AGI R&D projects spread across 37 countries.
Terminology
AGI is also known as strong AI, full AI, or general intelligent action. However, some academic sources reserve the term "strong AI" for computer programs that experience sentience or consciousness. In contrast, weak AI (or narrow AI) is able to solve one specific problem, but lacks general cognitive abilities. Some academic sources use "weak AI" to refer more broadly to any programs that neither experience consciousness nor have a mind in the same sense as humans.
Related concepts include human-level AI, transformative AI, and superintelligence.