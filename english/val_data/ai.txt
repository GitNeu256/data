Artificial intelligence (AI) is the intelligence of machines and software, as opposed to human or animal intelligence. It is also the discipline in computer science that develops and studies intelligent machines. Sometimes "AI" refers to the machines themselves.
AI technology is widely used in industry, government, and science. Well-known applications include advanced web search engines (e.g. Google Search), recommendation systems (used by YouTube, Amazon, Netflix), understanding human speech (e.g. Siri and Alexa), self-driving cars (e.g. Waymo), generative or creative tools ( ChatGPT and AI art), and competition at the highest levels in strategic games (e.g., chess and Go).
Artificial intelligence was founded as a discipline in 1956. However, funding and interest have increased significantly since 2012, when deep learning (deep learning) surpassed previous AI technologies.
The various subfields of AI research focus on specific goals and the use of specific tools; traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and robotics support. General intelligence (the ability to solve arbitrary problems) is one of the long-term goals of the field. To solve these problems, AI researchers have applied and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, statistics, operations research, and economics-based methods AI also draws on psychology, linguistics, philosophy, neuroscience, many other disciplines as well.
OBJECTIVES.
The general problem of simulating (or creating) intelligence is broken down into sub-problems. These consist of specific characteristics or capabilities that researchers expect from an intelligent system. The characteristics described below have received the most attention and cover the scope of AI research.
Reasoning and problem solving
Early researchers developed algorithms that mimicked the step-by-step reasoning used by humans to solve puzzles and make logical inferences; in the late 1980s and 1990s, methods were developed to deal with uncertain or incomplete information and used concepts from probability and economics.
Many of these algorithms were inadequate for solving large-scale inference problems because they suffered from a "combinatorial explosion" that slowed exponentially as the problem grew larger. Even humans rarely perform the kind of stepwise inference that early AI research was able to model. They solve most problems with fast, intuitive decisions. Accurate and efficient reasoning is an open problem.
Knowledge Representation
Knowledge representation and knowledge engineering allow AI programs to intelligently answer questions and make inferences about real-world facts. Formal knowledge representation is used in content-based indexing and retrieval, scenario interpretation, clinical decision support, knowledge discovery (mining "interesting" and actionable inferences from large databases), and other areas.
A knowledge base is a collection of knowledge expressed in a form that can be used by a program. An ontology is a set of objects, relations, concepts, and properties used in a particular knowledge domain. A knowledge base includes objects, properties, categories, relationships among objects, situations, events, states, time, cause and effect, knowledge about knowledge (what we know about what others know), default inferences (what humans assume to be true until told differently, and other facts are assumed to be true even if they change), and many other aspects or domains of knowledge that need to be represented. One of the most difficult problems in KR is the breadth of common sense knowledge (the set of atomic facts that the average person knows is enormous) and the unsymbolized form of most common sense knowledge (much of what one knows is not expressed as "facts" or "statements" that can be verbally expressed). It is.
Knowledge acquisition is the difficult problem of acquiring knowledge for AI applications. Modern AI collects knowledge by "scraping" the Internet (including Wikipedia). The knowledge itself is collected by volunteers and experts (who may or may not have agreed to provide work to AI companies) who have made the information public. This "crowdsourcing" technology does not guarantee that the knowledge is correct or reliable. Knowledge from large-scale language models (such as ChatGPT) is very unreliable and generates misinformation and falsehoods (known as "hallucinations"). Providing accurate knowledge for such modern AI applications is an open problem.
Planning and Decision-Making
An "agent" is one that perceives the world and takes action. Rational agents have goals and preferences and take actions to achieve them. In automated decision making, the agent has preferences - there are situations the agent prefers and there are situations it tries to avoid. The decision-making agent assigns a number (called "utility") to each situation that measures how much the agent prefers that situation. For each possible action, an "expected utility" can be calculated: the utility of all possible outcomes of that action, weighted by the probability of that outcome occurring. The action with the largest expected utility can then be selected.
In classical planning, the agent knows exactly what action will have what effect. However, in most real-world problems, the agent may not be certain about the situation he is in (it is "unknown" or "unobservable") and may not be certain what will happen after each possible action (it is not "deterministic"). We must make a probabilistic guess, choose an action, and then reevaluate the situation to see if that action worked. In some problems, the agent's preferences may be uncertain. These can be learned (e.g., by inverse reinforcement learning) or the agent can seek information to improve its preferences. Information value theory can be used to assess the value of exploratory and experimental behaviors. The space of possible future actions and situations is generally large enough to be intractable, so agents must take action and evaluate situations while not knowing what the outcome will be.
Markov decision processes include transition models that describe the probability that a particular action will change the state in a particular way, and reward functions that supply the utility of each state and the cost of each action. A policy associates a decision with each possible state. Policies can be computed (e.g., by iteration), heuristic, or learned.
Game theory describes the rational behavior of multiple interacting agents and is used in AI programs that involve other agents in decision making.
Learning
Machine learning is the study of programs that automatically improve the performance of a given task. Machine learning has been part of AI from the beginning.
There are several types of machine learning. Unsupervised learning analyzes a stream of data to find patterns and make predictions without other guidance. In supervised learning, a human must first label the input data, and there are two types: classification (the program must learn to predict which category the input belongs to) and regression (the program must infer a numerical function based on numerical input). In reinforcement learning, agents are rewarded for good responses and punished for bad ones. The agent learns to select answers that are classified as "good." Transfer learning is the application of knowledge gained from one problem to a new problem. Deep learning uses artificial neural networks for all these types of learning.
Computational learning theory can evaluate learners by computational complexity, sample complexity (how much data is required), or other optimization concepts.
Natural Language Processing
Natural language processing (NLP) allows programs to read, write, and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval, and question answering.
Early work based on Noam Chomsky's generative grammar and semantic networks made word sense disambiguation difficult unless restricted to a small region called the "micro-world" (due to common sense knowledge problems).
Modern deep learning techniques for NLP include word embeddings (how often one word appears near another), transformers (finding patterns in text), etc. In 2019, generatively pre-trained transformer (or "GPT") language models begin to produce coherent text, and by 2023 these models could score at human levels on bar exams, SATs, GREs, and many other real-world applications.