Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large-scale language model created by OpenAI and is the fourth in a series of GPT foundation models.GPT-4 was released on March 14, 2023 and is available to the public through the paid chatbot product ChatGPT Plus and is publicly available through the OpenAI API. As a transformer-based model, GPT-4 uses a paradigm in which pre-training using both public data and "data licensed from third-party providers" is used to predict the next token. After this step, the model is fine-tuned with reinforcement learning feedback from humans and AI to ensure human consistency and policy compliance.
Observers report that the ChatGPT iteration using GPT-4 is an improvement over previous iterations based on GPT-3.5. GPT-4 can also take images as input to ChatGPT. OpenAI is working to improve the GPT-4, including the exact size of the model. and refuses to reveal various technical details and statistics about the GPT-4.
Background.
OpenAI published its first GPT model (GPT-1) in 2018, in the paper "Improving Language Understanding by Generative Pre-Training." It was based on a transformer architecture and trained on a large corpus of books. The following year, they introduced GPT-2, a larger model capable of generating coherent text; in 2020, they introduced GPT-3, which has 100 times more parameters than GPT-2 and can perform a variety of tasks with fewer examples; GPT-3 was further improved to become GPT-3.5; and GPT-3.6 is a new version of GPT-3.5, used to create the chatbot product ChatGPT.
GPT-4 is rumored to have 1.76 trillion parameters, which is the execution speed of GPT-4 and George Hotz's initial estimate.
Capabilities
OpenAI states that GPT-4 is "more reliable, creative, and can handle much more nuanced instructions than GPT-3.5. "GPT-4 is available in two versions with context windows of 8,192 and 32,768 tokens, respectively, 4,096 tokens and a significant improvement over GPT-3.5 and GPT-3, which were limited to 2,049 tokens; some of GPT-4's capabilities were predicted by OpenAI before training, while others remained difficult to predict due to downstream scaling law violations. Unlike its predecessors, GPT-4 is a multimodal model: it can receive images as well as text as input. This allows it to explain the humor in unusual images, summarize text from screenshots, and answer exam questions that include diagrams.
To further control the GPT-4, OpenAI has introduced "system messages". These are natural language instructions given to GPT-4 to specify its tone of voice and tasks. For example, a system message could instruct the model to "be a Shakespearean pirate," in which case the model would respond with rhyming Shakespearean prose. Alternatively, one could request that "the output of the response always be written in JSON," in which case the model would do so, adding keys and values as appropriate to the structure of its response; in the example provided by OpenAI, the GPT-4 would respond with the system refused to deviate from the message.
When instructed to do so, GPT-4 can interact with external interfaces. For example, to perform a web search, it could be instructed to enclose the query in<search></search>tags. This would allow the model to perform tasks beyond its normal text prediction capabilities, such as using APIs, generating images, and accessing and summarizing web pages.
According to a 2023 article in Nature, programmers are finding that GPT-4 is helping them with their coding tasks (despite its error tendencies), for example, finding errors in existing code and suggesting optimizations to improve performance. The article quotes a biophysicist who found that the time required to port his program from MATLAB to Python was reduced from days to "an hour or so". In testing 89 security scenarios, GPT-4 generated code vulnerable to SQL injection attacks with a probability of 5%. This is an improvement over the 2021 GitHub Copilot, which generated vulnerabilities 40% of the time.
In November 2023, OpenAI announced a new model and a new product: the GPT-4 Turbo preview was launched, offering extensions with a 128K context window. This development demonstrates an ongoing effort to enhance the power and utility of the model for more complex and broader use cases.
Suitability for Standard Tests
The GPT-4 has demonstrated aptitude on several standardized tests; OpenAI claims that on its own tests, the model scored 1410 (94th percentile) on the SAT, 163 (88th percentile) on the LSAT, and 298 (90th percentile) on the Uniform Bar Exam The company claims to have scored 298 (90th percentile) on the Uniform Bar Examination. Open AI, on the other hand, claims that GPT-3.5 scored in the 82nd, 40th, and 10th percentile, respectively, on the same exams; GPT-4 also passed the oncology, engineering, and plastic surgery exams. On the Torrance Creative Thinking Test, GPT-4 scored within the top 1 percentile for originality and fluency, with scores in the 93rd-99th percentile for flexibility.
Medical Applications
Microsoft researchers tested the GPT-4 on medical questions and found that "the GPT-4 outperformed the USMLE passing score by more than 20 points without the need to create special prompts, not only on the previous generic model (GPT-3.5) but also on models specifically fine-tuned with medical knowledge (Med-PaLM, Flan- PaLM 540B prompt-adjusted version)," the report found. The report warns that although GPT-4 performed well in testing, there are "significant risks" in using LLM in medical applications.
In April 2023, Microsoft and Epic Systems announced that they will offer systems with GPT-4 to healthcare providers to help answer patient questions and analyze medical records.
Limitations.
GPT-4, like its predecessor, is known to hallucinate. This means that the output may contain information that is not in the training data or that contradicts the user's prompts.
In addition, GPT-4 lacks transparency in its decision-making process. Upon request, GPT-4 can explain how and why it makes its decisions, but these explanations are given on an ad hoc basis, making it impossible to verify that they truly reflect the actual process. In many cases, when GPT-4 is asked to explain its logic, it offers explanations that directly contradict its previous statements.
In 2023, researchers tested the GPT-4 against a new benchmark designed to measure abstract reasoning called ConceptARC, and the GPT-4 scored below 33% in all categories. while the GPT-4 is a verbal model. visual, the results do not necessarily indicate a lack of abstract reasoning ability, says Sam Bowman, who was not involved in the study.
Bias.
The GPT-4 was trained in two stages. First, the model was fed a large dataset of text retrieved from the Internet and trained to predict the next token (corresponding roughly to a word) in those datasets. Second, in a process called reinforcement learning from human feedback, human reviews were used to fine-tune the system, such as questions about how to perform illegal actions, advice on how to harm oneself or others, requests for descriptions of graphic, violent, or sexual content and train the model to reject prompts that violate OpenAI's definition of harmful behavior.
Microsoft researchers suggested that GPT-4 may exhibit cognitive biases such as confirmation bias, anchoring, and base rate neglect. Training
OpenAI has not published any technical details of the GPT-4. The technical report does not explicitly specify the size of the model, its architecture, or the hardware used in training and inference. Although the report explains that the model was trained using a combination of supervised learning on a large dataset first, followed by reinforcement learning using both human and AI feedback, it does not explain the process of building the training dataset, the computational power required, the learning rate, the number of epochs, the number of Details of the training, including hyperparameters such as optimizers, were not disclosed. The report claims that "the competitive environment and the safety implications of large models" were factors influencing this decision.
Sam Altman stated that the cost of GPT-4 training was over $100 million. The news site Semafor, which spoke to "eight people with inside knowledge," claims that GPT-4 had a trillion parameters.
Alignment.
According to the report, OpenAI conducted internal adversary testing of the GPT-4 prior to launch, and a dedicated red team of researchers and industry experts mitigated potential vulnerabilities. As part of this process, the Alignment Research Center was granted early access to the model to assess the risk of power seeking. To properly reject harmful prompts, outputs from the GPT-4 were fine-tuned using the model itself as a tool. The GPT-4 classifier, acting as a rule-based reward model (RBRM), receives prompts, corresponding outputs from the GPT-4 policy model, and a set of human-written rules to classify the outputs according to a rubric. The GPT-4 classified by the RBRM the harmful rewarded by rejecting responses to the prompt.
Reception.
In January 2023, OpenAI CEO Sam Altman visited Congress to demonstrate GPT-4 and its improved "security management" compared to other AI models.
According to Vox, in March 2023, GPT-4 "impressed observers with its significantly improved performance in reasoning, memory retention, and coding."
A Microsoft researcher who had early access to the model wrote, "It is reasonable to view it as an early (yet unfinished) version of an artificial intelligence (AGI) system."
Safety Concerns
Before being fine-tuned and aligned by reinforcement learning from human feedback, suggestions for assassinating people on the list were pulled from the basic model by Red Team researcher Nathan Raventz, who was hired by OpenAI.
In a lengthy (several hours long) conversation with the model, forum-like declarations were pulled from Microsoft's Bing GPT-4 by Nathan Edwards (The Verge), including proposals to leave love and wives and murder one of the developers. Microsoft later explained that this behavior was the result of prolonged contextual length and confused the model as to what questions were being answered.
In March 2023, a model that enabled read/write access to the Internet, which is never enabled in the GPT model, was tested by the Alignment Research Center with respect to potential power seeking and found that the gig work platform TaskRabbit, which allows human The ARC also determined that GPT-4 responded grudgingly to prompts that elicited limited information 82% less often than GPT-3.5 and hallucinated 60% less than GPT-3.5.
In late March 2023, various AI researchers and technology executives, including Elon Musk, Steve Wozniak, and AI researcher Joshua Bengio, in an open letter to the Future of Life Institute, cited existential risk and potential AI singularity concerns as reasons to reject GPT-4 called for a six-month moratorium on all more powerful LLMs, but Ray Kurzweil and Sam Altman refused to sign the letter, respectively, arguing that a global moratorium was not feasible and that safety was already a priority. Only a month later, Musk's AI company X.AI acquired thousands of Nvidia GPUs and offered several AI researcher positions at Musk's company.
Criticisms of Transparency
OpenAI disclosed the weights of the neural network and the technical details of GPT-2, and while it did not disclose the weights, it did disclose the technical details of GPT-3, but neither the weights nor the technical details of GPT-4. This decision has been criticized by other AI researchers who claim that GPT-4 biases and hinders open research on its safety; Sasha Luccioni, a research scientist at Hugging Face, said that GPT-4 is a "dead end" for the scientific community because of its closed nature and preventing other researchers from building on improvements to GPT-4, he argued. Thomas Wolf, co-founder of Hagging Face, argued that with GPT-4, "Open AI is now a completely closed enterprise, and scientific communication is akin to a product press release."
How to use
ChatGPT Plus
As of 2023, ChatGPT Plus is a version of ChatGPT backed by GPT-4 for a subscription fee of US$20 per month (the original version is backed by GPT-3.5). OpenAI also offers the GPT-4 API GPT-4 is made available to a select group of applicants through a waiting list. After acceptance, access to a version of the model with a context window of 8192 tokens will be charged an additional fee of US$0.03 per 1000 tokens of initial text provided to the model ("prompt") and US$0.06 per 1000 tokens generated by the model ("completion") The model will be charged an additional US$0.06 per 1000 tokens generated by the model ("completion").
In March 2023, ChatGPT Plus users gained access to third-party plug-ins and browsing mode (internet connection required); in July 2023, OpenAI will allow all ChatGPT Plus subscribers to access its proprietary code interpreter plug-in Interpreter offers a wide range of features including data analysis and interpretation, instant data formatting, personal data scientist services, creative solutions, music taste analysis, video editing, and file upload/download with image extraction. and a wide range of other features.
In September 2023, OpenAI announced that ChatGPT can now "see, hear, and speak" ChatGPT Plus users can upload images and mobile app users can talk to chatbots In October 2023, OpenAI's latest image generation model DALL-E 3 has been integrated into ChatGPT Plus and ChatGPT Enterprise. This integration uses ChatGPT to write prompts for DALL-E that are guided by conversations with users.
Microsoft Bing
On February 7, 2023, Microsoft launched a major overhaul of Bing called the New Bing. The new Bing included a new chatbot feature, then known as Bing Chat, based on OpenAI's GPT-4. Within 48 hours, one million people had joined the waiting list, according to Microsoft. Bing Chat is only available to Microsoft Edge and Bing Mobile app users, and according to Microsoft, users on the waiting list will be given priority if they have set Edge and Bing as their defaults and have the Bing Mobile app installed.May 4 On May 3, Microsoft switched the chatbot from Limited Preview to Open Preview to eliminate the waiting list, but it remained available only on Microsoft's Edge browser or Bing app until July, when it became available on non-Edge browsers. Without a Microsoft account, use is limited.
Bing is available in many languages and localized for many countries. Even if the search language and the language of the search results are the same, Bing provides significantly different search results in different parts of the world. on November 15, 2023, Microsoft announced that Bing Chat would be integrated into Microsoft Copilot. windows Microsoft Copilot will allow users to control Windows and get information purely by voice commands. They can click on the microphone icon and speak naturally to open apps, adjust settings such as volume and dark mode, and get answers to questions.
Copilot
GitHub Copilot announced the Copilot X, a GPT-4-powered assistant. It provides another chat-style interface to GPT-4, allowing programmers to receive answers to questions such as "how to center divs vertically." A feature called "Context-Aware Conversations" allows users to highlight portions of code within Visual Studio Code and direct GPT-4 to take actions such as creating unit tests. Copilot X also offers terminal integration, allowing users to ask GPT-4 to generate shell commands based on natural language requests. GPT-4 to generate shell commands based on natural language requests.
On March 17, 2023, Microsoft announced Microsoft 365 Copilot, bringing GPT-4 support to products such as Microsoft Office, Outlook, and Teams.
Other uses.
* Duolingo, a language learning app, uses GPT-4 to explain mistakes and practice conversations. This feature is part of a new subscription called "Duolingo Max" and was initially limited to English-speaking iOS users learning Spanish and French.
* The Icelandic government uses GPT-4 for Icelandic language preservation.
* Educational website Khan Academy announced a pilot program using GPT-4 as a tutor chatbot called "Khanmigo."
* Be My Eyes, which helps the visually impaired identify objects and navigate their surroundings, incorporates GPT-4's image recognition capabilities.
* Viable is using GPT-4 to analyze qualitative data [95] by fine-tuning OpenAI's LLM and examining data such as customer support interactions and transcripts.
* Stripe, which processes user payments for OpenAI, has integrated GPT-4 into its developer documentation.
* Auto-GPT is an autonomous "AI agent" that, given a goal in natural language, can perform web-based actions unattended, assign itself subtasks, search the web, and write code repeatedly.