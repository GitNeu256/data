Gemini is a family of multimodal large-scale language models developed by Google DeepMind to serve as a successor to LaMDA and PaLM 2. It consists of Gemini Ultra, Gemini Pro, and Gemini Nano, and was announced on December 6, 2023, positioning it as a competitor to OpenAI's GPT-4.
History
Development
Google announced Gemini, a large-scale language model (LLM) developed by its subsidiary Google Deep Mind, at the Google I/O keynote on May 10, 2023. It is positioned as a more powerful successor to PaLM 2, which was also announced at the same event, and Google CEO Sunder Pichai said Gemini is still in its early development stages. Unlike other LLMs, he said, Gemini is not trained on text corpora alone, but is designed to be multimodal, meaning that it can process multiple types of data simultaneously, including text, images, audio, video, and computer code. Developed as a collaboration between two Google divisions, DeepMind and Google Brain, which merged as Google DeepMind the previous month, DeepMind CEO Demis Hassabis, in an interview with Wired, touted Gemini's advanced capabilities. appealed to the public. He believes the algorithm can beat OpenAI's ChatGPT, which runs on GPT-4 and is growing in popularity and was being aggressively challenged by Google at LaMDA and Bard. Hassabis highlighted the strength of DeepMind's AlphaGo program, which gained worldwide attention in 2016 when it defeated Go champion Lee Sedol, and said Gemini would combine AlphaGo with other Google and DeepMind LLM capabilities.
In August 2023, The Information published a report outlining Google's Gemini roadmap, revealing that the company is targeting a late 2023 launch. According to the report, Google hoped to surpass OpenAI and other competitors by combining the conversational texting capabilities found in most LLMs with artificial intelligence-based image generation to create contextualized images and adapt to a wider range of use cases. Like Bard, Google co-founder Sergey Brin was called out of semi-retirement to help develop Gemini, along with hundreds of engineers from Google Brain and DeepMind. Since Gemini will be trained on transcripts of YouTube videos, lawyers were also brought in to filter out potentially copyrightable material.
With the impending launch of Gemini, OpenAI rushed to integrate multimodal capabilities similar to those of Gemini into GPT-4. The Information magazine reported in September that Google intended to offer customers through its Google Cloud Vertex AI service, LLM The Information reported in September that several companies have been granted early access to an "early version" of LLM, which Google intends to offer to customers through its Google Cloud vertex AI service. The magazine also said that Google is arming Gemini to compete with both GPT-4 and Microsoft's GitHub Copilot; on December 2, it reported that Google delayed the launch of Gemini from the following week to January 2024 because of problems with non-English prompts. He added that three launch events were planned in New York, Washington, D.C., and California.
Launch.
On December 6, 2023, Pichai and Hassabis announced Gemini 1.0 at a virtual press conference. Gemini 1.0 will consist of three models: the Gemini Ultra, designed for "very complex tasks"; the Gemini Pro, designed for "broad tasks"; and the Gemini Nano, designed for "on-device tasks." At launch, Gemini Pro and Nano were integrated into the Bard and Pixel 8 Pro smartphones, respectively, while Gemini Ultra was to be included in the Bard Advanced and made available to software developers in early 2024. Other products Google intended to incorporate Gemini into include search, advertising, Chrome, Duet AI on Google Workspace, and AlphaCode 2. Gemini will only be available in English. Touted as Google's "largest and most capable AI model" and designed to emulate human behavior, Gemini will not be widely used until the following year because it requires "extensive safety testing," the company said. Gemini is trained on Google's Tensor Processing Units (TPUs) and is powered by TPUs. The name is a nod to the merger of DeepMind and Google Brain and to NASA's Project Gemini.
Gemini Ultra is said to have outperformed GPT-4, Anthropic's Claude 2, Inflection AI's Inflection-2, Meta's LLaMA 2, and xAI's Grok 1 in various industry benchmarks, while Gemini Pro is said to have outperformed GPT-3.5 Gemini Pro is said to have outperformed GPT-3.5. Gemini Ultra is also the first language model to outperform human experts on the 57-subject Massive Multitask Language Understanding (MMLU) test, scoring in the 90th percentile. gemini Pro was launched on December 13 AI Studio and Vertex AI to Google Cloud customers on December 13, and Gemini Nano will be available to Android developers. Hasabis further revealed that Deep Mind is exploring ways to "combine Gemini with robotics to physically interact with the world. "Pursuant to Executive Order 14110, signed by President Joe Biden in October, Google will share Gemini Ultra's test results with the U.S. federal government, the company said it would share them with the government. Similarly, the company was in discussions with the UK government to comply with the principles outlined at the AI Safety Summit held at Bletchley Park in November.
Technical Specifications
The three Gemini models share the same software architecture. They are decoder-only transformers, modified to allow efficient learning and inference on the TPU. Context length is 32,768 tokens and supports multi-queries. two versions of Gemini Nano, Nano-1 (1.8 billion parameters) and Nano-2 (3.25 billion parameters), are extracted from the larger Gemini model and are They are designed for use in edge devices.
Because Gemini is multimodal, each context window can contain multiple input forms. The different modes can be interleaved and need not be presented in a fixed order, allowing for multimodal conversations. Input images may be of different resolutions, and video is input as a sequence of images. Audio is sampled at 16 kHz and converted into a sequence of tokens by a universal speech model. the Gemini dataset is multimodal and multilingual, "consisting of web documents, books and codes, and includes image, audio and video data."
Reception.
Gemini's launch began with months of intense speculation and anticipation, which MIT Technology Review described as "the peak of AI hype. "In August 2023, Dylan Patel and Daniel Nisibor of research firm SemiAnalysis said the release of Gemini "ate the world, blog post declaring that it would outperform GPT-4, and OpenAI CEO Sam Altman mocked the duo on X (formerly Twitter), while OpenAI co-founder and business tycoon Elon Musk asked, "Are the numbers wrong?" asked Hugh Langley of Business Insider, who said Gemini would be a make-or-break moment for Google, writing: "If Gemini is spectacular, it will overturn the narrative that Google has been outsmarted by Microsoft and OpenAI. If Gemini is spectacular, Google will be able to reverse the narrative that it has been outfoxed by Microsoft and Open AI. If it disappoints, it will embolden critics who say Google has fallen behind.
Oren Etzioni, professor emeritus at the University of Washington, reacting to the December 2023 announcement, predicted a "flash in the pan arms race" between Google and OpenAI. Professor Alexei Efros of the University of California, Berkeley, praised the potential of Gemini's multimodal approach, while Santa Fe Institute scientist Melanie Mitchell described Gemini as "very sophisticated." Professor Chirag Shah of the University of Washington was less impressed, likening Gemini's presentation to Apple's annual release of a new iPhone. Similarly, Percy Lian of Stanford University and Emily Bender of the University of Washington cautioned that it is difficult to interpret benchmark scores without insight into the training data used. Mark Sullivan, writing in Fast Company, opined that Google has an opportunity to challenge the iPhone's dominant market share and that Apple is unlikely to have the ability to develop a similar feature to Gemini in its Siri virtual assistant. Google faced criticism for the Gemini demo video, which was not done in real time.