A neural network can refer to either the neural circuit of a biological neuron (also called a biological neural network), or, in the case of an artificial neural network, an artificial neural network or a network of nodes.
Artificial neural networks are used to solve artificial intelligence (AI) problems and model the connections of biological neurons as weights between nodes. A positive weight reflects an excitatory connection, and a negative value means an inhibitory connection. All inputs are corrected and summed by weights. This activity is called a linear combination. Finally, the activation function controls the amplitude of the output. For example, the allowable output range is usually between 0 and 1, or between -1 and 1.
These artificial networks can be used for predictive modeling, adaptive control, and applications that can be trained through data sets. Self-learning arising from experience can occur within a network that can draw conclusions from a complex and seemingly unrelated set of information.
Overview
A biological neural network consists of a group of chemically connected or functionally related neurons. A single neuron could be connected to many other neurons, and the total number of neurons and connections in the network could be extensive. Connections, called synapses, usually form from axons to dendrites, but dendrite synapses and other connections are also possible. Apart from electrical signal transduction, there are other forms of signal transduction that result from the diffusion of neurotransmitters.
Artificial intelligence, cognitive modeling and neural networks are information processing paradigms inspired by how the biological nervous system processes data. Artificial intelligence and cognitive modeling try to simulate some characteristics of biological neural networks. In the field of artificial intelligence, we applied artificial neural networks to speech recognition, image analysis, and adaptive control, and succeeded in constructing software agents (computers and video games) and autonomous robots.
Historically, digital computers evolved from the von Neumann model and operated through the execution of explicit instructions through access to memory by many processors. On the other hand, the origin of neural networks is based on efforts to model information processing in biological systems. Unlike the Von Neumann model, neural network computing does not separate memory from processing.
Neural network theory helps to better identify how neurons in the brain work and provide the basis for efforts to create artificial intelligence.
History
A preliminary theoretical basis for modern neural networks was proposed independently by Alexander Bain (1873) and William James (1890). In their study, both thinking and physical activity were attributed to interactions between neurons in the brain.
For Bain, all activity led to the firing of a certain set of neurons. As the activity was repeated, the connection between those neurons was strengthened. According to his theory, this repetition was what led to the formation of memory. The general scientific community at the time was skeptical of Bain's theory because it needed what appeared to be an excessive number of neural connections in the brain. The brain is so complex that it has become clear that the "wiring" of the same brain can handle multiple problems and inputs.
James's theory was similar to that of Bain, but he suggested that memory and behavior were due to currents flowing between neurons in the brain. His model did not require an individual neural connection for each memory or action by focusing on the flow of electric current.
C.S.Sherrington (1898) conducted an experiment to test James's theory. He applied an electric current to the spinal cord of the rat. But instead of demonstrating the increase in current predicted by James, Sherrington found that the current strength decreases as the test continues over time. Importantly, this work led to the discovery of the concept of habituation.
Wilhelm Lenz (1920) and Erst Ising (1925) created and analyzed the Ising model, which is essentially a non-learning artificial recurrent neural network (RNN) consisting of neuron-like threshold elements. In 1972, Shunichi Amari adapted this architecture. His learning RNN was popularized by John Hopfield in 1982. McCulloch and Pitts (1943) also created a computational model of neural networks based on mathematics and algorithms. They are called the threshold logic of this model. These early models paved the way for dividing the path for neural network research into 2 different approaches. One approach focused on the biological processes of the brain and the other focused on the application of neural networks to artificial intelligence.
In the late 1940s psychologist Donald Hebb created a hypothesis of learning based on the mechanisms of neuroplasticity. Hebbia learning is considered to be a "typical" unsupervised learning rule, and subsequent variants were an early model for long-term augmentation. These ideas began to be applied to computational models on Turing's type B machine in 1948.
Farley and Clark (1954) first used calculators, then called calculators, and simulated the Heavian network at MIT. Other neural network calculators were created by Rochester, Holland, Habit, And Duda (1956).
Frank Rosenblatt (1958) created a perceptron, an algorithm for pattern recognition based on a two-layer learning computer network using simple addition and subtraction. In mathematical notation, Rosenblatt also described circuits that are not in the basic perceptron, such as exclusive-or circuits.
Some say that neural network research has stalled after the publication of machine learning research by Marvin Minsky and Seymour Papert (1969). They found 2 key problems with calculators that handle neural networks. The first problem was that single-layer neural networks could not handle exclusive or circuits. The second important issue is that computers are not sophisticated enough to effectively handle the long running time required by large neural networks, but by the time this book came out, how to train multi-layer perceptron (MLPs) was already known. The first deep Learning MLP was published in 1965 by Alexey Grigorevich Ivakhnenko and Valentin Lapa. The first deep Learning MLP trained by stochastic gradient descent was published by Shunichi AMARI in 1967. In a computer experiment conducted by Amari student Saito, a five-layer MLP with two mutable layers learns useful internal representations for classifying nonlinear separable pattern classes.
The study of neural networks was boosted when computers achieved greater processing power. The key to later progress was the backpropagation algorithm. This is an efficient application of the Leibniz chain rule (1673) to a network of differentiable nodes. It is also known as the reverse mode of auto-differentiation or reverse accumulation, due to Seppo Linnainmaa (1970). The term "backpropagation error" was introduced by Frank Rosenblatt in 1962, but Henry J did not have an implementation of this procedure. Kelly had a continuous precursor of propaganda back in 1960 already in the context of control theory. In 1982, Paul Werbos applied back propagation to mlp in a way that has become standard.
In the late 1970s and early 1980s, interest temporarily increased in the theoretical study of the Ising model on Cayley tree topology and large-scale neural networks by Wilhelm Lenz (1920) and Ernst Ising (1925). In 1981, the Ising model was solved precisely by Peter Barth for the general case of a closed Cayley tree (with loops) with arbitrary branching ratios and found to exhibit abnormal phase transition behavior in its local vertex and long-range site-to-site correlation.
Parallel distributed processing in the mid-1980s became popular under the name connectionism. The text of Rumelhart and McClelland (1986) provided a complete description of the use of connectedness in computers to simulate neural processes.
The neural network used in artificial intelligence has traditionally been seen as a simplified model of neural processing in the brain, since it is not clear to what extent the artificial neural network reflects the function of the brain, even though the relationship between this model and the biological architecture of the brain has been discussed.
Artificial intelligence
A neural network (NN) is an interconnected group of natural or artificial neurons using mathematical or computational models for information processing based on an approach of connectivity to computation, in the case of artificial neurons called artificial neural networks (ANN) or simulated neural networks (SNN). There is. In most cases, AN ANN is an adaptive system that changes its structure based on external or internal information flowing through the network.
In more practical terms, neural networks are nonlinear statistical data modeling or decision-making tools. They can be used to model complex relationships between inputs and outputs, or to find patterns in the data.
An artificial neural network includes a network of simple processing elements (artificial neurons) and can exhibit complex global behavior determined by the connection between processing elements and element parameters. Artificial neurons were first proposed in 1943 by neurophysiologist Warren McCulloch and logician Walter Pitts.
1. One of the classic types of artificial neural networks is the recurrent hopfield network.
The concept of neural networks appears to have been first proposed by Alan Turing in his 1948 paper Intelligent Machinery, which was called "type B unorganized machines."
The usefulness of an artificial neural network model lies in the fact that it can be used to infer a function from an observation and use it. Unsupervised neural networks can also be used to learn representations of inputs that capture the salient characteristics of the input distribution.See, for example, the Boltzmann machine (1983), and more recently, a deep learning algorithm that can implicitly learn the distribution function of observed data. Learning in neural networks is especially useful in applications where the complexity of data and tasks makes the manual design of such functions impractical.
Application
Neural networks can be used in a variety of fields. Tasks to which artificial neural networks are applied tend to fall into the following broad categories:
* Function approximation, or regression analysis, including time series prediction and modeling.
* Classification including pattern and sequence recognition, novelty detection and sequential decision making.
* Data processing including filtering, clustering, blind signal isolation and compression.
Applications of Ann include nonlinear system identification and control (vehicle control, process control), gameplay and decision making (backgammon, chess, racing), pattern recognition (radar systems, face recognition, object recognition), sequence recognition (gesture, voice, handwritten text recognition), medical diagnostics, financial applications, data mining (or data mining This includes knowledge discovery in the database ("KDD"), visualization, and email spam filtering. For example, it is possible to create a semantic profile of a user's interest that emerges from an image trained for object recognition.
Neuroscience
Theoretical and Computational neuroscience is a field related to the analysis and computational modeling of the biological nervous system. Since the nervous system is closely related to cognitive processes and behavior, this area is closely related to cognitive and behavioral modeling.
The aim of this field is to create a model of the biological nervous system to understand how biological systems work. To gain this understanding, neuroscientists need to understand the observed biological processes (data), the biologically plausible mechanisms for neural processing and learning (biological neural networks).
Type of model
It is defined at different levels of abstraction and models different aspects of the nervous system. They range from models of short-term behavior of individual neurons to models of dynamics of neural circuits arising from interactions between individual neurons, to models of behavior arising from abstract neural modules representing complete subsystems. These include models of long-term and short-term plasticity of the nervous system and its relationship to learning and memory, from individual neurons to the system level.
Connectivity
In 2020-8, scientists reported that by adding two-way connections, or appropriate feedback connections, they could accelerate and improve communication between and within the modular neural networks of the cerebral cortex of the brain, lowering the threshold for successful communication. They showed that by adding feedback connections between resonance pairs, a single pulse packet can propagate successfully across the network.
Criticism
Historically, a common criticism in neural networks, especially in robotics, has been that they require a large variety of training samples for real-world operations (however, for a single dimension, there are only 12 samples needed to get virtually 8% error). Because the learning machine needs a sufficiently representative example to capture the underlying structure that allows it to generalize to a new case. Dean Pomerleau is using neural networks to train robotic vehicles traveling on multiple types of roads (single-lane, multi-lane, dirt, etc.) in a study published in the paper "Knowledge-based Training of Artificial Neural Networks for Autonomous Robot Driving."). Much of his research is devoted to (1) extrapolating multiple training scenarios from a single training experience, and (2) maintaining the diversity of past training so that the system is not over-trained (for example, if a series of right turns are presented - one should not always learn to turn right). These problems are common in neural networks, where they have to be determined from a variety of responses, but for example, random shuffling of learning examples, using numerical optimization algorithms that do not take too large steps when changing network connections according to the examples, or using so-called minibars. This can be addressed in several ways by grouping examples by touch.
A former Scientific American columnist.K.Dewdney wrote in 1997, "Neural nets solve some toy problems, but the power of computation is so limited that I am surprised that everyone takes it seriously as a common problem-solving tool."
The discussion of Dewdney's position is that to implement a large and effective software neural network, you need to commit a lot of processing and storage resources, and the brain has hardware tailored to the task of processing signals through the graph of neurons, but it can be further developed in the most simplified form with von Neumann technology. In addition, designers of neural network systems often need to simulate the transmission of signals through many of these connections and the neurons associated with them.This often needs to be matched with an incredible amount of CPU processing power and time. Neural networks often produce effective programs, but they often do so at the expense of efficiency (which consumes considerable time and money).
The argument against Dewdney's position is that neural nets have been successfully used to solve many complex and diverse tasks, such as autonomous flying aircraft.
Technology writer Roger Bridgman commented on Dewdney's statement on the neural net:
	Neural networks, for example, are not only advertised on the high heavens, but also because they can create a successful net without understanding how it worked.The bunch of numbers that capture that behavior will be an "opaque and unreadable table" with all probability.It has no value as a scientific resource."
	Despite his emphatic declaration that science is not technology, Dewdney appears to be plundering the neural net as bad science, with most of the people who are devising them trying to be good engineers. An unreadable table that a useful machine can read is still worth having.
It is true that it is difficult to analyze what has been learned by artificial neural networks, but it is much easier than analyzing what has been learned by biological neural networks. In addition, the recent emphasis on explainability of AI has contributed to the development of methods for visualizing and explaining learned neural networks, in particular methods based on attention mechanisms. In addition, researchers involved in the search for neural network learning algorithms are gradually revealing the general principles for successful learning machines. For example, Bengio and LeCun (2007) have written articles on local and non-local learning, and shallow and deep architecture.
Some other criticisms have come from devotees of hybrid models (a combination of neural networks and symbolic approaches). They advocate mixing these 2 approaches and believe that hybrid models can better capture the mechanisms of the human mind (Sun and Bookman, 1990).
Recent improvements
While initial research was primarily concerned with the electrical properties of neurons, a particularly important part of recent research has been the exploration of the role of neuromodulators such as dopamine, acetylcholine, and serotonin in behavior and learning.
Biophysical models such as BCM theory are important in understanding the mechanisms of synaptic plasticity and have been applied in both computer science and neuroscience. Research is ongoing to understand the computational algorithms used in the brain, and recent biological evidence for radial basal networks and neural backpropagation is as a mechanism for processing the data.
Computational devices are created in CMOS for both biophysical simulation and neuromorphic computing. Recent efforts have shown promise to create nanodevices for very large-scale principal component analysis and convolution. If successful, these efforts will depend on learning, not programming, and will essentially be implemented, even if the first instantiation is actually a CMOS digital device.
Between 2009 and 2012, recurrent neural networks and deep feedforward neural networks, developed by the research group of Jürgen Schmidhuber of the Swiss AI lab IDSIA, have won 8 international competitions in pattern recognition and machine learning. For example, multi-dimensional long short term memory (lstm) won the 2009 Icdar (International Conference on Document Analysis And Recognition) in 3 contests for connected handwriting recognition without prior knowledge of 3 different languages.
Variants of the backpropagation algorithm, and unsupervised methods by Geoff Hinton and colleagues at the University of Toronto, are described in 1980's Neocognitron by Kunihiko Fukushima, and in David H. H.Similar to the "standard architecture of vision" inspired by simple and complex cells identified in the primary visual cortex by Hubel and Torsten Wiesel, it can be used to train deep, highly nonlinear neural architectures.
A radial basis function and a wavelet network are also introduced. These have been shown to provide the best approximate characteristics and have been applied to non-linear system identification and classification applications.
The deep learning feedforward network alternates the convolution layer and the maximum pooling layer, and places several pure classification layers on top of it. The fast GPU-based implementation of this approach has won several pattern recognition contests, including the IJCNN2011Traffic Sign Recognition Competition and the ISBI2012Segmentation of Neuronal Structures in Electron Microscopy Stacks challenge. Such neural networks were also the first artificial pattern recognizers to achieve competitive or superhuman human performance in benchmarks such as traffic sign recognition (IJCNN2012) and MNIST handwritten number problems by Yann LeCun and colleagues at Nyu.
Analytical and computational techniques derived from statistical physics of disordered systems can be extended to large-scale problems including machine learning to analyze the weight space of deep neural networks.