Generative Artificial Intelligence (also called Generative AI or GenAI) is artificial intelligence that can generate text, images, and other media using generative models. Generative AI models learn the patterns and structure of input training data and generate new data with similar characteristics.
In the early 2020s, advances in transformer-based deep neural networks led to a number of generative AI systems notable for accepting natural language prompts as input. These include large-scale language model chatbots such as ChatGPT, Bing Chat, Bard, and LLaMA, as well as text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.
Generative AI is used in a wide range of industries, including art, writing, software development, product design, healthcare, finance, gaming, marketing, and fashion. Investment in generative AI surged in the early 2020s, with large companies such as Microsoft, Google, and Baidu as well as numerous smaller companies developing generative AI models. However, there are also concerns about the potential misuse of generative AI, including cybercrime and the creation of fake news and deepfakes.
History
The discipline of artificial intelligence was founded in 1956 at a research workshop at Dartmouth College. Since its inception, scholars in the field have raised philosophical and ethical debates about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence. These notions of automatic art go back at least as far as the automata of ancient Greek civilization. There, inventors such as Daedalus and the Alexandrian heroes are described as having designed machines that could write sentences, produce sounds, and play music. The tradition of creative automata has flourished throughout history, such as Mairalde's automaton, created in the early 1800s.
Since the birth of AI in the 1950s, artists and researchers have used artificial intelligence to create works of art; in the early 1970s, Harold Cohen created and exhibited generative AI works produced by AARON, a computer program he created to generate paintings The exhibition was the first of its kind in the world.
Markov chains have long been used as a model for natural language since they were developed by Russian mathematician Andrei Markov in the early 20th century. Markov published his first paper on the subject in 1906, using Markov chains to analyze the vowel and consonant patterns in the novel Eugeny Onegin. Once a Markov chain is trained on a text corpus, it can be used as a probabilistic text generator.
Statistical models, including generative models, are often used in machine learning to model and predict data, and the advent of deep learning, which began in the late 2000s, has driven advances and research in image classification, speech recognition, natural language processing, and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.
In 2014, advances such as variational autoencoders and generative adversarial networks led to the first practical deep neural networks capable of learning generative rather than discriminative models of complex data such as images. These deep generative models were the first to be able to output entire images, not just image class labels.
In 2017, the Transformer network enabled the evolution of generative models, leading to the first generative pre-trained Transformer (GPT) in 2018. This was followed by GPT-2 in 2019, which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model. In 2021, DALL-E, a transformer-based pixel generation model, was released, followed by Midjourney and Stable Diffusion, where practical high-quality artificial intelligence art emerged from natural language prompts.
In March 2023, GPT-4 was released. The Microsoft Research team argued that "GPT-4 can reasonably be considered an early (yet unfinished) version of an artificial intelligence (AGI) system."
Modalities.
Generative AI systems are built by applying unsupervised or self-supervised machine learning to a data set. The capabilities of a generative AI system depend on the modality and type of dataset used.
Unimodal systems accept only one type of input, while multimodal systems can accept more than one type of input. For example, one version of OpenAI GPT-4 accepts both text and image input.
Text. 
Generative AI systems trained on words or word tokens include GPT-3, LaMDA, LLaMA, BLOOM, and GPT-4 (see list of large-scale language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as the underlying model for other tasks. Datasets include BookCorpus, Wikipedia, and others (see list of text corpora).
Code.
In addition to natural language texts, large language models can be trained on programming language texts to generate source code for new computer programs, e.g. OpenAI Codex.
Image
See also: Artificial Intelligence Art
The creation of high-quality visual art is a prominent application of generative AI. Many such works of art have received public awards and recognition.
Generative AI systems trained on image sets with text captions include Imagen, DALL-E, Midjourney, Adobe Firefly, and Stable Diffusion (see Artificial Intelligence Art, Generative Art, Synthetic Media). These are often used for text-to-image generation and neural style transfer. Datasets include LAION-5B and others (see Computer Vision Datasets).
Music
Generative AI systems such as MusicLM and MusicGen can train audio waveforms of recorded music with text annotations and generate new music samples based on textual descriptions such as a calm violin melody backed by a distorted guitar riff The system can generate new music samples based on textual descriptions such as a calm violin melody backed by a distorted guitar riff.
Video
Generative AI trained with annotated video can generate temporally coherent video clips, such as RunwayML's Gen1 and Gen2 and Meta Platforms' Make-A-Video.
Molecular
Generative AI systems can be trained on amino acid sequences or molecular representations such as SMILES representing DNA or proteins; these systems, such as AlphaFold, have been used for protein structure prediction and drug discovery. Datasets include a variety of biological datasets.
Robotics.
Generative AI can also train robotic systems to move and generate new trajectories for motion planning and navigation. For example, Google Labs' UniPi uses prompts such as "pick up the blue bowl" or "wipe the plate with the yellow sponge" to control the movements of a robotic arm; multimodal "visual-language-action" models such as Google's RT-2 can respond to user prompts and visual input to It is capable of making rudimentary inferences in response to user prompts and visual input. For example, if a user is instructed to pick up an extinct dinosaur toy at a table full of animals and other toys, it will pick up the animal.
Planning
The term generative AI planning or generative planning was used in the 1980s and 1990s to refer to AI planning systems, particularly computer-aided process planning, used to generate sequences of actions to reach specified goals.
Generative AI planning systems used symbolic AI methods such as state-space search and constraint satisfaction, which were "relatively mature" techniques in the early 1990s. They were used to generate decision plans such as crisis action plans for the military, process plans for manufacturing, and autonomous spacecraft prototypes. Software and Hardware
Generative AI models are used in chatbot products such as ChatGPT, programming tools such as GitHub Copilot, text-to-image products such as Midjourney, and text-to-video products such as Runway Gen-2. Generative AI functionality has been integrated into a variety of existing commercial products, including Microsoft Office, Google Photos, and Adobe Photoshop. In addition, many generative AI models, such as Stable Diffusion and the LLaMA language model, are available as open source software.
Smaller generative AI models with up to billions of parameters can be run on smartphones, embedded devices, and personal computers. For example, LLaMA-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4, and one version of Stable Diffusion can run on an iPhone 11.
Larger models with tens of billions of parameters can be run on a laptop or desktop computer. To achieve acceptable speeds, models of this size might require GPU chips produced by Nvidia or AMD, or accelerators such as the Neural Engine in Apple's silicon products. For example, a 65 billion parameter version of LLaMA could be configured to run on a desktop PC.
Language models with hundreds of billions of parameters, such as GPT-4 and PaLM, are typically run on data center computers with an array of GPUs (such as Nvidia's H100) or AI accelerator chips (such as Google's TPU). These very large models are usually accessed as cloud services via the Internet.
In 2022, the U.S. New Export Controls on Advanced Computing and Semiconductors to China imposed restrictions on exports to China of GPUs and AI accelerator chips used for generative AI. chips such as the Nvidia A800 and Biren Technology BR104 were developed to meet sanction requirements developed to meet the requirements of the sanctions.
Concerns.
The development of generative AI has sparked concern from governments, businesses, and individuals, leading to protests, legal action, calls for a moratorium on AI experimentation, and action by several governments In a July 2023 UN Security Council briefing, Secretary-General Antonio Guterres stated that "generative AI has has enormous potential for good and evil at scale," and while AI may "turbo-charge global development" and contribute to a $10-15 trillion global economy by 2030, its malicious use could cause "horrific levels of death and destruction on an unimaginable scale, widespread trauma, and deep psychological damage".
Loss of Jobs
Since the early days of AI development, ELIZA developer Joseph Weizenbaum and other researchers have debated whether computers should actually be allowed to do the jobs that computers can do, given the differences between computers and humans and between quantitative calculations and qualitative, value-based decisions The development of image-generating AI contributed to the Hollywood labor dispute of 2023; in April 2023, it was reported that 70% of Chinese game illustrator jobs had been lost due to image-generating AI; in July 2023, the development of generative AI contributed to the Hollywood labor dispute of 2023; and in December 2023, a new image-generating AI was reportedly used by a Chinese game illustrator to create a new game. Fran Drescher, president of the Screen Actors Guild, declared during the 2023 SAG-AFTRA strike that "artificial intelligence will bring an existential crisis to the creative professions."
Deep Fake.
Deepfakes (a compound of "deep learning" and "fake") are AI-generated media in which a person in an existing image or video is replaced by someone else's likeness using an artificial neural network. Deep fakes have attracted widespread attention and concern because of their use in celebrity pornography videos deep fakes, revenge pornography, fake news, hoaxes, and financial fraud. As a result, both industry and government have called for action to detect and limit the use of deepfakes.
Cybercrime.
The ability of generative AI to create realistic fake content has been exploited in many types of cybercrime, including phishing scams. Deep-fake videos and audio have been used to create disinformation and scams. Schumann Gosemajumder, former head of Google Fraud, predicts that deepfake videos will initially cause a media frenzy, but will soon become commonplace and thus more dangerous. Cybercriminals are creating large-scale language models focused on fraud, such as WormGPT and FraudGPT.
Abuse in Journalism
In January 2023, Futurism.com reported that CNET had written at least 77 articles using an undisclosed in-house AI tool. After the news broke, CNET published corrections to 41 articles.
In April 2023, the German tabloid Die Aktuelle published an AI-generated fake interview with former racing driver Michael Schumacher. The cover story included the passage "deceptively real" (deceptively real), and the interview ended with an admission that it had been created by AI. The editor-in-chief was fired shortly thereafter.
REGULATIONS
In the European Union, the proposed Artificial Intelligence Act would require disclosure of copyrighted material used to train generative AI systems and label AI-generated output as such.
In the United States, a group of companies including OpenAI, Alphabet, and Meta signed a voluntary agreement with the White House in July 2023 to watermark AI-generated content.
In China, the Interim Measures for the Administration of Generative AI Services introduced by the China Cyberspace Administration regulate generative AI for public use. It includes requirements for watermarking generated images and videos, regulations on the quality of training data and labels, restrictions on personal data collection, and guidelines that generative AI must "adhere to the core values of socialism.